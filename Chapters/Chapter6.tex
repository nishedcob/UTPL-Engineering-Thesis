% Chapter 6

\chapter{Despliegue}
\label{capitulo6}

\section{Plan de Despliegue}
En el curso del desarrollo, depuracion y ejecuccion de pruebas llegó a ser evidente en enorme consumo de recursos necesarios para levantar todos los servicios desarrollados y auxiliares a la vez, razon por el cual, se ha visto la necesidad de un rediseño de forma mas liviana de la manera en que se despliegue todos los componentes integrados a la aplicacion para con ello terminar las fases mencionadas anteriormente y dar paso a ejecuccion en ambientes de pocos recursos, tanto en el ambito de desarrollo como de produccion. En la implementacion original de la arquitectura fisica para el desarrollo, se habia planteado una colleccion de maquinas virtuales quienes representarian servidores distintas dentro de una red, pero para temas de optimizar recursos, se ha realizado los siguientes cambios los cuales se documentan a lo largo de este capitulo:
\begin{itemize}
	\item Kubernetes (backend de virtualizacion) se ubica en una maquina virtual de Xen (con paravirtualizacion activa para aumentar el rendimiento del sistema virtualizado) dado que el mismo, por temas de seguridad, debe seguir de una forma aislada. De esta forma se simula que esta en un servidor aparte, sea fisico o virtual (se recomienda mejor virtualizar todo el cluster final de Kubernetes en algun hipervisor de tipo 1 para garantizar mayor seguridad y aislamiento) pero sin la mayor parte de las perdidas de rendimiento que se dio con MiniKube (alojado en VirtualBox).
    \item Los servicios auxiliares en lugar de ser maquinas virtuales de Xen ahora son contenedores de Docker.
    \item Los servicios desarrollados se los han convertido en servicios (Systemd) del sistema operativo, no tanto por temas de rendimiento (aunque se podria mejorar el rendimiento de esta forma, asignandoles a un usuario con mayor prioridad de ejecuccion como el usuario root\footnote{Pero realizarlo esta afuera del alcance de este tesis, una solucion asi de software tampoco puede cambiar los recursos fisicos de la maquina.}\footnote{Nunca se debe asignar un servicio que se consume en la red externa a algun usuario con privilegios de superusuario, como root, ya que el mismo abre todo el sistema operativo a un nuevo vector de ataque por el mismo servicio. En este caso debe ser un nuevo usuario, preferiblemente uno por cada servicio, con acceso restingido que tiene mayor prioridad de ejecucion para sus procesos.}) si no por temas de facilitar la administracion del mismo.
    \item La integracion de los servicios con NGinX para que el mismo puede protegerlos y operar en la capacidad de proxy inversa, proxy de terminacion SSL/TLS, servidor de archivos estaticos y validador de peticiones sin mayor perdida de rendimiento.
\end{itemize}
% TODO
% diagrama de red/fisica

\section{Preperaciones del Ambiente de Despliegue}
Para preperar el ambiente de despliegue se lo ve pertinente planificar direcciones IP, dominios y puertos para los varios servicios que requieren ser levantados:
\begin{description}
	\item[Maquina Fisica] con Debian 9.x para Servicios y Docker: \textit{10.10.10.1}
    \begin{description}
    	\item[NGinX] \textit{http://0.0.0.0:80}
        \begin{itemize}
            \item \textit{http://10.10.10.1:80} \& \textit{http://git.localhost:80} -> GitWeb
            \item \textit{http://gitedu.localhost:80} -> GitEDU
            \item \textit{http://edunube.localhost:80} -> EduNube
            \item \textit{http://gitsrvendpoint.localhost:80} -> GitServerHTTPEndpoint
            \item \textit{http://gitlab.localhost:80} -> GitLab
            \item \textit{http://moodle.localhost:80} -> Moodle
        \end{itemize}
        \item[GitEDU] \textit{http://0.0.0.0:8000}
        \item[EduNube] \textit{http://0.0.0.0:8001}\footnote{Este puerto esta en conflicto con el Dashboard de Kubernetes, o se podria cambiar este puerto o montar el Dashboard de Kubernetes solo en la maquina virtual si es que fuera el caso}
        \item[GitServerHTTPEndpoint] \textit{http://0.0.0.0:8002}
        \item[Docker] \textit{10.10.10.1}
        \begin{description}
        	\item[MySQL] \textit{0.0.0.0:3306} -> \textit{moodledb:3306}
        	\item[Moodle] \textit{0.0.0.0:8201} -> \textit{moodle:80}
        	\item[GitLab CE] \textit{10.10.10.1}
            \begin{itemize}
            	\item \textit{0.0.0.0:8143} -> \textit{gitlab:443}
            	\item \textit{0.0.0.0:8101} -> \textit{gitlab:80}
            	\item \textit{0.0.0.0:8122} -> \textit{gitlab:22}
            \end{itemize}
        \end{description}
    \end{description}
    \item[Maquina Virtual (Xen)] con Debian 9.x para el Cluster (solo 1 nodo maestro) de Kubernetes: \textit{10.10.10.12}
\end{description}

\subsubsection{Moodle en Docker}
La instalacion de Moodle en Docker consiste de los siguientes pasos:
\begin{enumerate}
	\item Bajar el imagen de Docker oficial de MySQL:
    \begin{lstlisting}    
docker pull mysql
    \end{lstlisting}
    \item Bajar un imagen de Docker de Moodle:
    \begin{lstlisting}    
docker pull jauer/moodle
    \end{lstlisting}
    \item Ejecutar el imagen de MySQL en el fondo (-d) con un nombre idenficable (moodledb), paso de puertos (10.10.10.1:3306 -> moodledb:3306), un volumen de persistencia para el motor de base de datos, nombres de bases de datos, usuarios y contraseñas de MySQL y una peticion de que siempre se reinicia el contenedor a lo que muere con algun error:
    \begin{lstlisting}    
docker run -d --name moodledb -p 3306:3306 -v \
/srv/moodle/mysql:/var/lib/mysql -e \
MYSQL_DATABASE=moodle -e MYSQL_ROOT_PASSWORD=moodle \
-e MYSQL_USER=moodle -e MYSQL_PASSWORD=moodle \
--restart always mysql
    \end{lstlisting}
    \item Ejecutar el imagen de Moodle con opciones similares al anterior, con un enlace a la base de datos con un dominio local de DB, metadatos del url en que debe responder y ocupar el puerto 8201 local como puerto 80 del contenedor (un passthrough):
    \begin{lstlisting}    
docker run -d -P --name moodle --link moodledb:DB\
-e MOODLE_URL=http://10.10.10.1:8201 -p 8201:80 \
-v /srv/moodle/data:/var/moodledata \
--restart always jhardison/moodle
    \end{lstlisting}
    \item Y finalmente visitamos http://10.10.10.1:8201/ para terminar la instalacion inicial de Moodle y realizar su configuracion inicial.
\end{enumerate}

\subsubsection{GitLab en Docker}
Para instalar GitLab en Docker, se sigue pasos similares a los vistos previamente con Moodle:
% TODO: Cite
%https://hub.docker.com/r/gitlab/gitlab-ce/
%https://docs.gitlab.com/omnibus/docker/
\begin{enumerate}
	\item Bajar el imagen de Docker:
    \begin{lstlisting}    
docker pull gitlab/gitlab-ce
    \end{lstlisting}
    \item Ejecutar el imagen de Docker:
    \begin{lstlisting}    
docker run --detach --hostname 10.10.10.1 \
--publish 8143:443 --publish 8101:80 \
--publish 8122:22 --name gitlab --restart always \
--volume /srv/gitlab/config:/etc/gitlab \
--volume /srv/gitlab/logs:/var/log/gitlab \
--volume /srv/gitlab/data:/var/opt/gitlab \
gitlab/gitlab-ce:latest
    \end{lstlisting}
    \item Visitar http://10.10.10.1:8101/ para cambiar la contraseña de root
\end{enumerate}

\index{Hipervisor} \index{Virtualización} \index{Contenedor}
\subsubsection{Máquina Virtual de Xen}
Con el fin de proteger la maquina fisica contra usuarios finales, sean maliciosos o solo sin conocimientos adecuados, hay la necesidad de que el ambiente que ejecuta codigo sea aislado con virtualizacion. Pero el rendimiento de esta maquina virtual necesita ser maximizada para poder permitir su uso con un minimo de recursos. Es, por lo tanto, que se ha propuesta utilizar una maquina virtual de Xen de baja nivel con mejores de rendimiento con la tecnologia de paravirtualizacion con la finalidad de que esta misma logra ofrecer alta aislamiento, y por lo tanto seguridad, frente una alta rendimiento.

\paragraph{Construción de Servidor Virtualizado para Cluster de Kubernetes}
Las caracteristicas minimas que pide Kubernetes para su nodo maestro son 2 nucleos y 2 GiB de RAM, es por aquello razon que se crea una maquina virtual paravirtualizada con estas mismas caracteristicas. En el curso del año que se ha trabajado este trabajo de titulacion la comunidad de Debian se ha logrado arreglar  el bug que antes causó problemas la ultima vez que se realizó una maquina virtual nueva de Debian 9 y es con este motivo que se puede crear una maquina virtual nueva sin ninguna necesidad para pasos adicionales:
\begin{lstlisting}
xen-create-image --hostname=debian-k8s-master \
--ip=10.10.10.12 --netmask=255.255.255.0 \
--gateway=10.10.10.1 --memory=2048mb --vcpus=2 \
--lvm=Xephyr-VG --pygrub --dist=stretch --force \
--size=10240mb --swap=1024mb
\end{lstlisting}
% TODO:
% see Screenshot_2017-12-29_15-21-49.png

\paragraph{Instalación de Docker}
Para utilizar Kubernetes dentro de esta maquina virtual es necesario primero contarnos con una instalacion de Docker. Kubernetes no garantiza que va a funcionar con las ultimas versiones de Docker ya que el API de Docker cambia constantemente, especialmente con actualizaciones de seguridad, pero de esta misma forma para la seguridad de la misma, queremos contar con la misma forma estable. Se instala de la siguiente manera en Debian (para otros sistemas operativos, a lo mucho solo se tendria que cambiar el gestor de paquetes apt por el respectivo de su sistema):
\begin{enumerate}
	\item Actualizar el sistema operativo
    \begin{lstlisting}
apt update
apt upgrade
    \end{lstlisting}
    \item Instalar curl si es que no esta instalado previamente
    \begin{lstlisting}
apt install curl
    \end{lstlisting}
    \item Bajar el instalador actual de Docker
    \begin{lstlisting}
curl -fsSL get.docker.com -o get-docker.sh
    \end{lstlisting}
    \item Ejecutar el instalador de Docker
    \begin{lstlisting}
sh get-docker.sh
    \end{lstlisting}
\end{enumerate}
% TODO: see Screenshot_2017-12-29_15-31-49.png

\paragraph{Instalación de Cluster de Kubernetes}
% TODO: Cite
%https://kubernetes.io/docs/setup/independent/install-kubeadm/
Para instalar el cluster de Kubernetes, el proceso es relativamente sencillo con una harramienta que se llama \texttt{kubeadm} que se encarga de levantar, gestionar y bajar nodos del cluster. Primero para instalar el mismo:
\begin{enumerate}
	\item Debemos tener suporte en el gestor de paquetes APT para el protocolo HTTPS:
    \begin{lstlisting}
apt update && apt install -y apt-transport-https
    \end{lstlisting}	
	\item Agregamos el repositorio de Kubernetes para Debian y Ubuntu:
    \begin{lstlisting}
curl -s \
	https://packages.cloud.google.com/apt/doc/apt-key.gpg \
	| apt-key add -
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb http://apt.kubernetes.io/ kubernetes-xenial main
EOF
    \end{lstlisting}
    \item Actualizamos los indices de APT y procedemos a instalar:
    \begin{lstlisting}
apt-get update
apt-get install -y kubelet kubeadm kubectl
    \end{lstlisting}
\end{enumerate}

El levantamiento de un nodo maestro basica se puede hacer con el commando:
    \begin{lstlisting}
kubeadm init
    \end{lstlisting}
Que utiliza todos los valores por defecto, pero Kubernetes requiere para su funcionamiento algun driver de red de los cuales se ha elegido Flannel ya que es el más sencillo y no necesitamos mayor funcionalidad como Switches programables, ni enrutamiento o ACLs en las redes de nuestro cluster debido a que no se busca levantar sistemas de produccion aqui, solo contendores independientes y obviamente otros drivers de red con mayor funcionalidad tienen un costo de rendimiento mayor. Si es que se levanto el cluster con el comando anterior, se lo puede destruir con el siguiente commando: 
    \begin{lstlisting}
kubeadm reset
    \end{lstlisting}
Ya que Flannel requiere que se define el rango de IPs con que se trabajara el cluster como 10.244.0.0/16\footnote{Si, parece que tiene que ser exactamente este rango y no suporta mas que $65,536$ contenedores al mismo tiempo, pero eso debe ser suficiente para el proposito actual.}, por lo tanto en realidad, para trabajar con Flannel es necesario agregar un argumento al commando de levantamiento del cluster como se lo indica a continuacion:
    \begin{lstlisting}
kubeadm init --pod-network-cidr=10.244.0.0/16
    \end{lstlisting}
Esto se genera una salida como la que se demuestra a continuacion:
    \begin{lstlisting}
To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

You can now join any number of machines by running the following on each node
as root:

  kubeadm join --token 655cb5.2275aa7df206fe69 10.10.10.12:6443 --discovery-token-ca-cert-hash sha256:4919df120063c4535fd03e909ce11dfe9e6448f8a767be914e86b16660d267c8
    \end{lstlisting}

Por defecto Kubernetes no permite que el nodo maestro aloje contenedores como una politica de seguridad, pero en este caso se quiere levantar un cluster de un solo nodo y por lo tanto se requiere cambiar esta politica con el siguiente commando:
    \begin{lstlisting}
KUBECONFIG=/etc/kubernetes/admin.conf kubectl taint nodes --all node-role.kubernetes.io/master-
    \end{lstlisting}
El parametro de KUBECO

%# permit execution on master node

%# save credentials to home folder
%mkdir -p $HOME/.kube
%cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
%chown $(id -u):$(id -g) $HOME/.kube/config

%# test connection
%kubectl version

%#https://kubernetes.io/docs/concepts/cluster-administration/networking/
%# install pod network (Flannel Driver)
%sysctl net.bridge.bridge-nf-call-iptables=1
%cat sysctl.conf
%cat >> /etc/sysctl.conf << EOF
%
%# For Kubectl Flannel
%net.bridge.bridge-nf-call-iptables = 1
%
%EOF
%
%apt install net-tools
%apt install git # necesario para clonar repositorios dentro del cluster, si no se instala, solo job/pi y pod/utility funcionaran
%# check that sshd is running/listening on external interface (port 22 is normal)
%# otherwise apt install openssh-server
%netstat -tupln

%vim.tiny /etc/ssh/sshd_config
%PermitRootLogin yes

%systemctl restart sshd

%# from host:
%scp root@10.10.10.12:/etc/kubernetes/admin.conf .
%kubectl --kubeconfig ./admin.conf get nodes

%mv admin.conf k8s.xen.master.admin.conf
%cp k8s.xen.master.admin.conf ~/.kube/config.xen
%cp ~/.kube/config ~/.kube/config.minikube
%cp ~/.kube/config.xen ~/.kube/config
%kubectl version
\subparagraph{Validación de Cluster de Kubernetes}
%cd kubernetes/
%kubectl create -f debian-pod.yaml
%kubectl get pods/utility
%kubectl describe pods/utility
%kubectl create -f debian-pod-2.yaml
%for manifest in `ls *.json`; do
%    kubectl create -f $manifest;
%done
%kubectl get jobs
%# not all will succeed, some point to git repos (http://192.168.99.1) that only minikube has access to
%watch -n 15 "kubectl get jobs"
%# First to finish:
%kubectl describe jobs/pi
%# Pod Created: pi-kf8zv
%kubectl describe pods/pi-kf8zv
%# see output of job
%kubectl logs jobs/pi

% TODO: under consideration if time
%\paragraph{Interfaz de Administracion}
%kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml
%kubectl proxy
\index{Contenedor} \index{Virtualización} \index{Hipervisor}

\section{Despliegue}
% TODO:
% servicios y su asignacion de puertos
% GitEDU - 8000/HTTP = gitedu.localhost
% EduNube - 8001/HTTP = edunube.localhost
% GitServerHTTPEndpoint - 8002/HTTP = gitsrvendpoint.localhost
% aux services (redir NGinX):
%		http://git.localhost:80 -> GitWeb
%		http://gitedu.localhost:80 -> GitEDU
%		http://edunube.localhost:80 -> EduNube
%		http://gitsrvendpoint.localhost:80 -> GitServerHTTPEndpoint
%		http://gitlab.localhost:80 -> GitLab
%		http://moodle.localhost:80 -> Moodle

\subsection{GitEDU}

\subsection{EduNube}

\subsection{GitServerHTTPEndpoint}

\section{Pruebas del Despliegue y Resultados}

